# 消息队列

**MQ组件**：选择器、通道、缓存区。

比较核心的场景是：**解耦**，**异步**，**削峰**

> 场景：给第三方发送商品，走mq，避免直接rpc请求超时；保证业务逻辑无异常，出异常就异常池，人介入
>
> 买基金有待确认，敏感数据处理耗时复杂，大宗交易涉及审核，异步处理。
>
> 同步binlog数据，新增-修改-删除是按顺序的，不能就弄成了删除-修改-新增等等。

缺点：

1. 系统可用性降低：引入的外部依赖越多，越容易挂掉，万一MQ挂了怎么办，牵连系统都崩溃。

2. 系统复杂度提高：消息重复消费，消息丢失，消息传递顺序性。
3. 一致性问题：A系统成功了，BCD系统有失败的，数据就不一致了。

| 特性       | ActiveMQ               | RabbitMQ                                         | RocketMQ                                | Kafka                                                        |
| ---------- | ---------------------- | ------------------------------------------------ | --------------------------------------- | ------------------------------------------------------------ |
| 单机吞吐量 | 万级                   | 万级                                             | 10万级，高吞吐                          | 10万级，高吞吐，配置大数据类系统进行实时数据计算，日志采集   |
| topic数量  |                        |                                                  | 几百/几千，吞吐量有较小幅度下降（优势） | 几十/几百，吞吐量大幅下降，所以不宜过多，否则要增加机器资源  |
| 时效       | ms级                   | 微秒级，延迟最低                                 | ms级                                    | ms级以内                                                     |
| 可用性     | 基于主从架构时效高可用 | 基于主从架构实现高可用                           | 非常高，分布式架构                      | 非常高，分布式，一个数据多个副本，不会丢失数据，不会不可用   |
| 消息可靠性 | 较低概率丢失           | 基本不丢                                         | 参数优化配置，0丢失                     | 参数优化配置，0丢失                                          |
| 功能支持   | MQ领域的功能极其完备   | 基于erlang开发，并发能力很强，性能极好，延时很低 | MQ功能比较完善，分布式，拓展性好        | 只支持简单的MQ功能，在大数据领域实时计算和采集日志大规模使用 |

**RabbitMQ的exchange类型**：direct、fanout、topic、headers。

**RabbitMQ的高可用**：是基于主从（非分布式）做高可用。三种模式如下

1. 单机模式。
2. 普通集群模式（无高可用性）：在多台机器启动多个RabbitMQ实例，每个机器启动一个，创建的queue，只会放在一个RabbitMQ实例上，但是每个实例都同步queue的元数据（元数据可以认为是queue的一些配置信息，通过元数据，可以找到queue所在实例），消费的时候，实际链接到了另一个实例，那个实例会从queue所在实例上拉取数据过来。缺点一来数据传输频繁，二来queue所在节点挂掉就找不回了（可开持久化）。
3. 镜像集群模式（高可用性）：创建的queue，无论元数据还是queue里的消息都会存在于多个实例中，就是每个RabbitMQ节点都有这个queue一个完整镜像，包含queue的全部数据，写消息时，自动同步到多个实例queue上。缺点是同步开销大，消耗带宽也多，数据大到装不下就麻烦了。

**Kafka的高可用**：message包括：消息长度、版本号、CRC校验码、具体消息。

**Kafka基本架构**：由多个broker组成，每个broker是一个节点，你创建的topic，这个topic可以划分为多个partition，每个partition可以存在于不同的broker上，每个partition就放一部分数据。

这就是天然的分布式消息队列，就是说一个topic的数据，是分散放在多个机器上的，每个机器就放一部分数据。

实际上Kafka的高可用，就是在于给这些broker创建在不同机器上的副本，只有一个leader，leader负责把数据同步到所有的follower，读写数据都只在leader。写数据时需要leader和follower全部成功，消费只有leader，但是也需要所有follower同步成功返回ack，这个数据才会被消费者读到。

**重复消费问题**：例如消费完数据要ack一下的，但是进程被kill没有发，误以为还没消费，重启项目之后又收到了。涉及到消费的幂等性，避免数据有重复。解决方向有下面这些：

> 1. 数据库写库，根据主键查下，这条数据有了，就不插入了，update下就好。
> 2. 写redis的，就没事，因为每次都是set，天然幂等性。
> 3. 上面两个都不是，就让生产者发送每条数据加个全局唯一id，类似订单id之类的，到redis查下之前是否消费过，没有消费过，现在消费了，就再写到redis。
> 4. 基于数据库的唯一键来保证重复数据不会插入多条。

**消息丢失**：

> 丢失的可能：1.消息在传入过程中丢失，2.MQ挂了，消息跟着没了，3.消费者收到消息还没处理就挂了。

第一个，RabbitMQ有事务channel.txSelect，发送消息没被mq成功收到就回滚事务channel.txRollback，然后重试发送消息，收到了，那么可以提交事务channel.txCommit。这么弄基本上吞吐量会下来，因为太耗性能。

为了不丢，可以开启confirm模式，生产者设置开启confirm模式之后，每次写消息都会分配一个唯一的id，写入RabbitMQ了，MQ会回传一个ack消息，说ok了，如果RabbitMQ没能处理这个消息，会回调你的一个nack接口，说失败了，你可以重试，而且你可以结合这个机制在内存唯一每个消息id的状态，超过一定时间没有收到回调，就重发。（waitForConfirm/回调）

第二个在MQ做持久化，步骤：1. 创建queue时设置持久化元数据，2.发送消息deliveryMode设置为2才行。（创建channel时有参数设置true）

第三个也是要做ack，关闭RabbitMQ自动ack，让消费者完主动ack回MQ（basicAck方法）。

kafka避免数据丢失做法则是要求partition至少两个副本，leader至少感知一个follower没掉队，生产者写入数据必须要写入所有副本之后才是写成功，写入失败，无限重试。

**消息顺序执行**：

1. RabbitMQ：拆分到多个queue，每个queue一个consumer；或者一个queue对应一个consumer，然后这个consumer内部用内存队列做排队，然后分发给底层不同的worker来处理。
2. Kafka：一个topic一个partition一个consumer内部单线程消费但不会用。写N个内存queue，具有相同key的数据都到同一个内存queue；对于N个线程，每个线程分别消费一个内存queue即可。

**消息大量堆积**：

* 先修复consumer，确保其恢复消费速度。
* 新建一个topic，partition是原来的10倍，临时建立好原先10倍的queue数量。
* 然后写一个临时的分发数据的consumer程序，这个程序部署上去消费积压的数据，消费之后不做耗时的处理，直接均匀轮询写入临时建立好的10倍数量的queue。
* 临时征用10倍的机器来部署consumer，每一批consumer消费一个临时queue的数据，这种做法相当于临时将queue资源和consumer资源扩大10倍，以正常10倍的速度来消费数据。
* 等快速消费完积压数据之后，得恢复原先部署的架构，重新用原来的consumer机器来消费消息。

**mq中的消息过期失效了**：有些数据设置了过期时间，但是大量积压下没有被消费，则被直接丢失了。一般可以在不活跃时间，重查出数据再跑。

**mq写满了**：按消息大量积压的来不及了，只能写程序消费一个丢弃一个，然后在按不活跃数据重查数据再跑。

**mq消息确认**：Rabbitmq生产者有channel.waitForConfirms()机制/事务（但是回滚动会把全部都回滚，性能一般）。消费者有1-自动应答，2-手动应答（channel.basicAck(envelope.getDeliveryTag(), false);），失败basicReject（..））。自动应答存在缺陷，消息被消费者接收到就应答，但是如果消费者消费消息失败，这时候会造成消息丢失。手动应答我们可以手工控制，在消息被消费者消息完之后再手工给予应答，这样消息不会丢失。